{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2024 Semester 1\n",
    "\n",
    "## Assignment 1: Wine quality classification with K-NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**     `1172598`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "wine_train = pd.read_csv('winequality-train.csv')\n",
    "wine_test = pd.read_csv('winequality-test.csv')\n",
    "\n",
    "def KNN_Classifier(k, df_test, df_train):\n",
    "    labels = []\n",
    "    for index, row in df_test.drop(columns=['quality']).iterrows():\n",
    "        #print(index)\n",
    "        distance_arr = []\n",
    "        for index1, row1 in df_train.drop(columns=['quality']).iterrows():\n",
    "            dis = 0\n",
    "            for i in range(len(df_test.columns)-1):\n",
    "                dis = dis + pow(row.iloc[i] - row1.iloc[i], 2)\n",
    "            distance_arr.append(pow(dis, 1/2))\n",
    "        df_temp = df_train.assign(distance=distance_arr)\n",
    "        df_temp = df_temp.sort_values('distance')\n",
    "        if (k == 1):\n",
    "            labels.append(df_temp['quality'].iloc[0])\n",
    "        else:\n",
    "            values = df_temp['quality'][0:k-1].tolist()\n",
    "            for i in range(len(values)):\n",
    "                good = 0\n",
    "                bad = 0\n",
    "                if (values[i] == 0):\n",
    "                    bad = bad + 1\n",
    "                else:\n",
    "                    good = good + 1\n",
    "            if (good == bad):\n",
    "                if (values[k/2 - 1] == values[k/2]):\n",
    "                    if (random.randint(1, 2) == 1):\n",
    "                        labels.append(values[k/2 - 1])\n",
    "                    else:\n",
    "                        labels.append(values[k/2])\n",
    "                else:\n",
    "                    labels.append(values[0])\n",
    "            elif (good > bad):\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    return labels\n",
    "\n",
    "labels = KNN_Classifier(1, wine_test[0:101], wine_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 1-NN classification\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7129\n"
     ]
    }
   ],
   "source": [
    "def Find_Proportion(df_test, labels_classified):\n",
    "    labels_test = df_test['quality'].tolist()\n",
    "    count = 0\n",
    "    for i in range(len(labels_classified)):\n",
    "        if (labels_test[i] == labels_classified[i]):\n",
    "            count = count + 1\n",
    "    return float(count)/float(len(labels_classified))\n",
    "\n",
    "print(\"{:0.4f}\".format(Find_Proportion(wine_test[0:101], labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalization\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model extensions\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1\n",
    "Compare the performance of your best 1-NN model from Question 3 to a Gaussian naive Bayes model on this dataset (you may use library functions to implement the Gaussian naive Bayes model). In your write-up, state the accuracy of the naive Bayes model and identify instances where the two models disagree. Why do the two models classify these instances differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2\n",
    "Implement two additional distance measures for your K-NN model: cosine similarity and Mahalanobis distance (you may use library functions for these distance measures). Do 1-NN classification using each of these new distance measures and the three normalization options from Question 3. Discuss how the new distance metrics compare to Euclidean distance and how each metric is affected by normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3\n",
    "Implement either of the two K-NN weighting strategies discussed in lecture (inverse linear distance or inverse distance). Compare the performance of the weighted and majority vote models for a few different values of K. In your write-up, discuss how weighting strategy and the value of K affect the model's decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4\n",
    "Measure the empirical distribution of class labels in the training dataset (what percentage of the training data comes from each class). Then evaluate the distribution of labels predicted by your K-NN model for the test data, for a range of values for K. Does the class distribution of the predicted labels match the class distribution of the training data? Explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
